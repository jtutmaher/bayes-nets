{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Bayes Nets and Exact Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information contained in this notebook can be derived from the following sources:\n",
    " - Sheldon Ross, \"A First Course in Probability, 7th Edition\", Pearson Prentice Hall, 2006 \n",
    " - Zoubin Ghahramani, \"Learning Dynamic Bayesian Networks,\" Department of Computer Science at University of Toronto, 1997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian vs Frequentists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistcs, there are several ways to interpret state spaces and events. Two common interpretations are the Bayesian (conditional) and Frequentist approaches. The distinction between the two can be understood via their definitions. \n",
    "<br>\n",
    ">$\\textbf{Frequentist:}$ A Frequentist defines probability in terms of relative frequency. For a given sample space, S, the probability that an event E occurs is definted as: $$\\lim_{n \\rightarrow \\infty} \\frac{n(E)}{n} = P(E),$$ where n(E) is the number of times a given event occurs, divided by n trials. In this case, the interpretation depends on the relatively frequency of the given event as the number of trials approaches infinity, and the $\\it{assumption}$ that it converges to a constant value in this limit. This assumption must be taken as an axiom of the interpretation, since there is no mathematically rigorous way to prove that a second set of trials will not produce a different limiting value for an arbitrary S.\n",
    "\n",
    "<br>\n",
    ">$\\textbf{Bayesian:}$ A Bayesian may use other variables in the sample space, S, to more accurately define probability. More formally, this can be defined as: $$P(E|F) = \\frac{P(E \\cap F)}{P(F)}.$$ This allows Bayesians to derive P(E) given information about another ancillary variable - in this case F. The assumption is that related evidence should be taken into account when computing an event's probability. \n",
    "\n",
    "<br>\n",
    "At face value, these two interpretations do not seem to be in direct opposition. However, they have drastic practical implications. Consider the following scenario. You roll 2 dice. One stays on the table, showing a 3, the other rolls off the table under a chair. You want to know the probability that you rolled a 7 without observing the second dice. \n",
    "\n",
    "<br>\n",
    "A $\\it{Frequentist}$ would conduct a set of trials, and compute $$\\lim_{n \\rightarrow \\infty} \\frac{n(E)}{n}.$$ In this case, they would find that the probability approaches 1/6, assuming a fair set of dice (there are 6 ways to sum to 7 for a pair of dice, over 36 possible outcomes). A $\\it{Bayesian}$, on the other hand, would use the fact that one dice is 3, and infer that the other one must be 4 in order to equal 7. Since the other dice has a 1/6 chance of landing on 4, the probability would be 1/6. \n",
    "\n",
    "<br>\n",
    "It turns out the the Bayesian interpretation is vastly more powerful in the context of machine learning. It allows us to tap into a $\\it{prior}$ distribution, and use real-world observables for related variables to compute a corresponding $\\it{posterior}$ distribution for our variable of interest. It also allows us to decompose an arbitrary joint probability distribution for a sample space, S, as a product of conditional probabilities.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Probabilities as Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider an abstract sample space composed of 4 random variables, W, X, Y, and Z. We don't know the relationships initially, but we can $\\it{write down}$ a joint probability function for this space: $$ P(W,X,Y,Z) = P(W)P(X|W)P(Y|W,X)P(Z|W,X,Y).$$ \n",
    "<br>\n",
    "Obviously this formula tells us very little information. It does not tell us how the variables are related, and does not allow us to isolate observable variables. The solution is to $\\it{define}$ the relationships between the variables by either flat-out $\\it{guessing}$, or using domain-expertise or historical data for those variables. Let's say we define X and W to be conditionally independent, an appropriate factorization in this case would be: $$P(W,X,Y,Z) = P(W)P(X)P(Y|W)P(Z|Y,X).$$ \n",
    "\n",
    "<br>\n",
    "Now - we have simplified the joint probability distribution of the system drastically. Graphically, we can represent this factorization as follows: \n",
    "<img src=\"imgs/bn1.png\" style=\"width: 200px;\">\n",
    "\n",
    "<br>\n",
    "There are some general rules to remember about Bayes Nets:\n",
    " - All Bayes Nets are directed, acyclic graphs\n",
    " - Variables (nodes) can be continuous or discrete random variables\n",
    " - Single connected Bayes Nets can leverage a Belief Propagation algorithm for inferencing\n",
    " - Multiply connected Bayes Nets (graphs with loops) can leverage a Junction Tree algorithm for inferencing\n",
    " - Many factorizations exist for a given joint probability, and there are several methods that can be leveraged to determine if a Bayes Net if performing optimally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belief Propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bayesian.bbn import build_bbn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEFINE BBN NODES AND CPTs\n",
    "def Pollution_Node(P):\n",
    "    '''Pollution'''\n",
    "    if P == 'high':\n",
    "        return 0.1\n",
    "    elif P == 'low':\n",
    "        return 0.9\n",
    "\n",
    "\n",
    "def Smoker_Node(S):\n",
    "    '''Smoker'''\n",
    "    if S is True:\n",
    "        return 0.3\n",
    "    elif S is False:\n",
    "        return 0.7\n",
    "\n",
    "\n",
    "def Cancer_Node(P, S, C):\n",
    "    '''Cancer'''\n",
    "    table = dict()\n",
    "    table['ttt'] = 0.05\n",
    "    table['ttf'] = 0.95\n",
    "    table['tft'] = 0.02\n",
    "    table['tff'] = 0.98\n",
    "    table['ftt'] = 0.03\n",
    "    table['ftf'] = 0.97\n",
    "    table['fft'] = 0.001\n",
    "    table['fff'] = 0.999\n",
    "    key = ''\n",
    "    key = key + 't' if P == 'high' else key + 'f'\n",
    "    key = key + 't' if S else key + 'f'\n",
    "    key = key + 't' if C else key + 'f'\n",
    "    return table[key]\n",
    "\n",
    "\n",
    "def Xray_Node(C, X):\n",
    "    '''X-ray'''\n",
    "    table = dict()\n",
    "    table['tt'] = 0.9\n",
    "    table['tf'] = 0.1\n",
    "    table['ft'] = 0.2\n",
    "    table['ff'] = 0.8\n",
    "    key = ''\n",
    "    key = key + 't' if C else key + 'f'\n",
    "    key = key + 't' if X else key + 'f'\n",
    "    return table[key]\n",
    "\n",
    "\n",
    "def Dyspnoeia_Node(C, D):\n",
    "    '''Dyspnoeia'''\n",
    "    table = dict()\n",
    "    table['tt'] = 0.65\n",
    "    table['tf'] = 0.35\n",
    "    table['ft'] = 0.3\n",
    "    table['ff'] = 0.7\n",
    "    key = ''\n",
    "    key = key + 't' if C else key + 'f'\n",
    "    key = key + 't' if D else key + 'f'\n",
    "    return table[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "| Node | Value | Marginal |\n",
      "+------+-------+----------+\n",
      "| C    | False | 0.988370 |\n",
      "| C    | True  | 0.011630 |\n",
      "| D    | False | 0.695929 |\n",
      "| D    | True  | 0.304070 |\n",
      "| P    | high  | 0.100000 |\n",
      "| P    | low   | 0.900000 |\n",
      "| S    | False | 0.700000 |\n",
      "| S    | True  | 0.300000 |\n",
      "| X    | False | 0.791859 |\n",
      "| X    | True  | 0.208141 |\n",
      "+------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "g = build_bbn(Pollution_Node, Smoker_Node, Cancer_Node, Xray_Node, Dyspnoeia_Node,domains={'P': ['low', 'high']})\n",
    "g.q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "| Node | Value | Marginal |\n",
      "+------+-------+----------+\n",
      "| C    | False | 0.971000 |\n",
      "| C    | True  | 0.029000 |\n",
      "| D    | False | 0.689850 |\n",
      "| D    | True  | 0.310150 |\n",
      "| P    | low   | 0.000000 |\n",
      "| P*   | \u001b[92mhigh*\u001b[0m | 1.000000 |\n",
      "| S    | False | 0.700000 |\n",
      "| S    | True  | 0.300000 |\n",
      "| X    | False | 0.779700 |\n",
      "| X    | True  | 0.220300 |\n",
      "+------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "g.q(P='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "| Node | Value | Marginal |\n",
      "+------+-------+----------+\n",
      "| C    | False | 0.975139 |\n",
      "| C    | True  | 0.024861 |\n",
      "| D    | False | 0.000000 |\n",
      "| D*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| P    | high  | 0.101999 |\n",
      "| P    | low   | 0.898001 |\n",
      "| S    | False | 0.692966 |\n",
      "| S    | True  | 0.307034 |\n",
      "| X    | False | 0.782597 |\n",
      "| X    | True  | 0.217403 |\n",
      "+------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "g.q(D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "| Node | Value | Marginal |\n",
      "+------+-------+----------+\n",
      "| C    | False | 0.968000 |\n",
      "| C    | True  | 0.032000 |\n",
      "| D    | False | 0.688800 |\n",
      "| D    | True  | 0.311200 |\n",
      "| P    | high  | 0.100000 |\n",
      "| P    | low   | 0.900000 |\n",
      "| S    | False | 0.000000 |\n",
      "| S*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| X    | False | 0.777600 |\n",
      "| X    | True  | 0.222400 |\n",
      "+------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "g.q(S=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "| Node | Value | Marginal |\n",
      "+------+-------+----------+\n",
      "| C    | False | 0.000000 |\n",
      "| C*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| D    | False | 0.350000 |\n",
      "| D    | True  | 0.650000 |\n",
      "| P    | high  | 0.156250 |\n",
      "| P    | low   | 0.843750 |\n",
      "| S    | False | 0.000000 |\n",
      "| S*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| X    | False | 0.100000 |\n",
      "| X    | True  | 0.900000 |\n",
      "+------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "g.q(C=True, S=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "| Node | Value | Marginal |\n",
      "+------+-------+----------+\n",
      "| C    | False | 0.660870 |\n",
      "| C    | True  | 0.339130 |\n",
      "| D    | False | 0.000000 |\n",
      "| D*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| P    | low   | 0.000000 |\n",
      "| P*   | \u001b[92mhigh*\u001b[0m | 1.000000 |\n",
      "| S    | False | 0.000000 |\n",
      "| S*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "| X    | False | 0.000000 |\n",
      "| X*   | \u001b[92mTrue*\u001b[0m | 1.000000 |\n",
      "+------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "g.q(D=True,S=True,P='high',X=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
